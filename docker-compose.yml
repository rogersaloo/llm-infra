version: '3.9'

services:
  redis:
    image: redis
    container_name: llama2_redis_1
    runtime: nvidia
    environment:
      - NVIDIA_VISIBLE_DEVICES=all
    ports:
      - "6379:6379"
    networks:
      - backend

  web:
    build: .
    command: ["uvicorn", "app:app", "--host", "0.0.0.0", "--port", "80"]
    volumes:
      - .:/app
    ports:
      - 8000:80
    depends_on:
      - redis
    networks:
      - backend

  worker:
    build: .
    command: celery -A celery_worker worker --loglevel=info
    runtime: nvidia
    environment:
      - NVIDIA_VISIBLE_DEVICES=all
    volumes:
      - .:/app
    depends_on:
      - redis
    networks:
      - backend


networks:
  backend:
    external: true

